# 《这就是搜索引擎核心技术详解》相关

 - [搜索引擎及其技术架构](https://github.com/luobotiantang/JavaRelatedBooks/blob/master/md/ThisIsTheSearchEngineCoreTechnology.md)  
 
     - [搜索引擎的重要地位](#搜索引擎的重要地位)
 
     - [搜索引擎技术发展史](#搜索引擎技术发展史)
 
     - [搜索引擎的3个目标](#搜索引擎的3个目标)
 
     - [搜索引擎的3个核心问题](#搜索引擎的3个核心问题)
 
     - [搜索引擎的技术架构](#搜索引擎的技术架构)
 
     - [搜索引擎架构图](https://www.processon.com/view/link/5ed34f437d9c080702854f3f)
 
 - [网络爬虫](#网络爬虫)
 
     - [通用爬虫框架](#通用爬虫框架)
 
     - [优秀爬虫的特性](#优秀爬虫的特性)
 
     - [爬虫质量的评价标准](#爬虫质量的评价标准)
 
     - [抓取策略](#抓取策略)
 
     - [网页更新策略](#网页更新策略)
 
     - [暗网抓取](#暗网抓取)
 
     - [分布式爬虫](#分布式爬虫)
 
 - [搜索引擎索引](#搜索引擎索引)  
 
     - [索引基础](#索引基础)
 
 ### 搜索引擎的重要地位
     由于目前互联网技术的爆炸性增长，信息过载的问题就目前来说越来越严重，由于互联网个性化的发展趋势越逐步展现，普通用户发布信息的成本
     越来越低，这个问题将会更加严重。这就是搜索引擎越来越重要的基础背景，搜索是目前解决信息过载的相对有效的方式，在没有更有效的替代解
     决方式出来之前，搜索引擎作为互联网网站和应用的入口及处于行业制高点的重要地位只会增强。
     
 ### 搜索引擎技术发展史
     1、分类目录
        采取分类目录的方式，纯人工方式并未采取什么高深的技术。如Yahoo、hao123这个时代的代表。
     2、文本检索
        采用经典的信息检索模型，采用布尔模型、向量空间模型或者概率模型，来查询用户的关键词和网页文本内容的相关程度。但是并未用到网页
        之间丰富的链接关系。早起的搜索引擎如AltaVista、Excite等大都采取这种模式。
     3、链接分析
        充分利用网页的链接关系，并深度挖掘和利用了网页链接所代表的含义。通常而言网页链接代表了一种推荐关系，所以通过链接分析可以在海
        量内容中找到重要的网页。如Google率先提出并使用PageRank链接分析技术。
     4、用户中心
        目前的搜索引擎大都可以归入第三代，即以理解用户需求为核心。
        目前搜索引擎大都致力于解决如下问题：如何能够理解用户发出的某个很短的查询词背后包含的真正需求，所以这一代的搜索引擎称之为以用
                                       户为中心的一代。
 ### 搜索引擎的3个目标
     应用形式：用户输入查询词，搜索引擎返回搜索结果。 
     1、更全
        索引的网页数量。可以通过提高网络爬虫相关技术来达到此目标。
     2、更快
        索引相关技术、缓存等技术的提出都是直接为了达到此目的。                                   
     3、更准
        如何使得搜索结果"更准"是最为关键的目标。(排序技术、链接分析技术、用户研究) 
 ### 搜索引擎的3个核心问题
     搜索引擎如何能够搜得更准是其最重要的目标。如何搜得更准涉及3个核心问题。
     1、用户真正的需求是什么
     2、哪些信息是和用户需求真正相关的
     3、哪些信息是用户可以依赖的      
 ### 搜索引擎的技术架构
     作为互联网应用中最具技术含量的应用之一，优秀的搜索引擎需要复杂的架构和算法，以此来支撑对海量数据的获取、存储，以即对用户查询的快
     速而准确的响应。
 ### 网络爬虫
     网络爬虫的作用
         高效的下载系统，将目前网页数以百亿计的网页数据传送到本地，在本地形成互联网网页的镜像备份。
 ### 通用爬虫框架
     首先从互联网页面中精心选择一部分网页，以这些网页的链接地址作为种子URL，将这些种子URL放入待抓取URL队列中，爬虫从待抓取URL队列依
     次读取，并将URL通过DNS解析，把链接地址转换为网站服务器对应的IP地址。然后将其和网页相对路径名称交给网页下载器，网页下载器负责页
     面内容的下载。对于下载到本地的网页，一方面将其存储到页面库中，等待建立索引等后续处理；另一方面将下载过的网页URL放入已抓取URL队
     列中，这个队列记载了爬虫系统已经下载过的网页URL，以避免网页的重复抓取。对于刚下载的网页，从中抽取所包含的所有链接信息，并在已抓
     取URL队列中检查，如果发现链接还没有被抓取过，则将这个URL放入待抓取URL队列末尾，在之后的抓取调度中会下载这个URL对应的网页。如此
     这般，形成循环，直到待抓取URL队列为空，这代表着爬虫系统已将能够抓取的网页尽数抓完，此时形成了一轮完整的抓取过程。
     爬虫划分以下3种类型
        1、批量型爬虫(Batch Crawler)
           有明确的抓取范围和目标
        2、增量型爬虫(Incremental Crawler)
           更新已有网页
        3、垂直型爬虫(Focused Crawler)
           关注特定主题内容或者属于特定行业的网页
 ### 优秀爬虫的特性
     1、高性能
        爬虫下载网页的抓取速度，常见的评价方式是以爬虫每秒能够下载的网页数量作为性能指标。
     2、可扩展性
        爬虫需要抓取网页数量巨大，即使单个爬虫的性能很高，要将所有网页都下载到本地，仍然需要相当长的时间周期，为了尽可能的缩短时间
        周期，爬虫系统应该有很好的可扩展性，即很容易通过增加抓取服务器和爬虫数量来达到此目的。
        分布式，增加并发性。
     3、健壮性
        服务器宕机，能够恢复之前抓取的内容和数据结构
     4、友好性
        1、保护网站的部分私密性
           A：爬虫禁抓协议
           B：网页禁抓标记
        2、减少抓取网站的网络负载 
           爬虫访问网站频率过高，会给服务器造成很大的访问压力，类似DOS攻击的效果。 
 ### 爬虫质量的评价标准
     1、抓取网页覆盖率
     2、抓取网页时新性
     3、抓取网页重要性
     决定了爬虫系统的质量和性能
        A：抓取策略
        B：网页更新策略
        C：暗网抓取
        D：分布式爬虫
     Google的两套爬虫系统
        A：Fresh Bot(以秒为更新周期)
        B：Deep Crawl Bot(以天为更新周期)           
 ### 抓取策略
     宽度优先遍历策略:
         将新下载网页追加到待抓取URL队列末尾。
     非完全PageRank策略:
         PageRank是一种链接分析算法，可以用来衡量网页的重要性.可以用PageRank的思想来对URL优先级进行排序，但这里有个问题，
         PageRank是个全局性算法，也就是说当所有网页都下载完成后，其计算结果才是可靠的，而爬虫的目的是下载网页，在运行中只能看到
         一部分页面，所以在抓取阶段的网页是无法获得可靠的PageRank得分的。
         对于已经下载的网页，加上待抓取URL队列中的URL一起，形成网页集合，在此集合内进行PageRank计算，计算完成后，将带抓取URL队
         列里的网页按照PageRank得分由高到低排序，形成的序列就是爬虫接下来应该依次抓取的URL列表，这也是为何称之为"非完全PageRank"
         的原因。
         如果每次新抓取到一个网页，就将所有已经下载的网页重新计算新的非完全PageRank值，明显效率太低，在现实中是不可行的。一个折中
         的办法是：每当新下载的网页攒够K个，将所有下载页面重新计算一遍新的非完全PageRank,这样的效率还勉强可以接受。
         但是又引来了新的问题：在展开下一轮PageRank计算之前，从新下载的网页抽取出包含的链接，很有可能这些链接的重要性非常高，理应
         优先下载这种情况该如何解决？非完全PageRank赋予这些新抽取出来但是又没有PageRank值的网页一个临时PageRank值，将这个网页的
         所有入链传导的PageRank值汇总，作为临时PageRank值，如果这个值比待抓取URL队列中已经计算出来的PageRank值的网页高，那么就
         优先下载这个URL。
     OCIP策略:
         Online Page Importance Computation,在线页面重要性计算，可以将其看作是一种改进的PageRank算法。在算法开始之前，每个互
         联网页面都赋予相同的"现金"cash，每当下载了某个页面P后，P将自己拥有的"现金"平均分配给页面中包含的链接页面，把自己的"现金"
         清空。而对于待抓取URL队列中的网页，则根据手头拥有的现金金额多少排序，优先下载现金最充裕的网页。OCIP从大的框架上与PageRank
         思路基本一致，区别在于：PageRank每次需要迭代计算，而OCIP策略不需要迭代过程，所以计算速度远远快于PageRank，适合实时计算
         使用。
     大站优先策略: 
         以网站为单位来衡量网页的重要性，对于待抓取URL队列中的网页，根据所属网站归类，其本质思想倾向于优先下载大型网站。
 ### 网页更新策略
     对于已经抓取的网页还要保持其内容和互联网页面内容的同步(可能抓取的内容已经删除了)，这取决于爬虫所采取的网页更新策略。
     历史参考策略:
         过去频繁更新的网页，那么将来也会频繁更新。所以，为了预估某个网页何时进行更新，可以参考其历史更新情况来做出决定。
         这种方法往往利用泊松过程来对网页的变化进行建模，根据每个网页过去的变动情况，利用模型预测将来何时内容再次发生变化。
         注：抓取策略应该忽略掉广告栏或者导航栏这种不重要的区域的频繁变化，而集中在主题内容的变化探测和建模上。
     用户体验策略:
         根据用户搜索排名进行更新
     聚类抽样策略:
         上面两种策略严重依赖网页的历史更新信息，因为这是能够进行后续计算的基础。但是现实中，为每个网页保存历史信息，会使搜索系统
         增加额外负担。但是如果没有历史信息就无法按照这两种思路去预估其更新周期。聚类抽样策略即是为了解决上述缺点而提出的。
         聚类抽样策略认为：网页具有一些属性，根据这些属性可以预测其更新周期，具有相似属性的网页，其更新周期也是类似的。
         能够体现网页更新周期的属性特征划分为两大类：静态特征和动态特征。
         静态特征：页面的内容、图片数量、页面大小、链接深度、PageRank值等十几种。
         动态特征：体现了静态特征随着时间的变化情况，比如图片数量的变化情况，入链出链的变化情况。
         聚类抽样策略效果好于前两种更新策略，但是对以亿计的网页进行聚类，其难度也是非常巨大的。
 ### 暗网抓取  
     Deep Web Crawling   
     所谓暗网：指目前搜索引擎爬虫按照常规方式很难抓取到的互联网页面。          
     如前所述，搜索引擎爬虫依赖页面中的链接关系发现新的页面，但是很多网站的内容是以数据库方式存储的，典型的例子就是一些垂直领域的
     网站，比如携程旅行网的机票数据，很难有显示链接指向数据库的记录，往往是用户输入查询之后来获得相关数据。
     为了能够对暗网数据进行索引，需要研发与常规爬虫机制不同的系统，这类爬虫被称作暗网爬虫。
     目的：将暗网数据从数据库中挖掘出来，并将其加入搜索引擎的索引，这样用户在搜索时便可利用这些数据，增加信息覆盖程度。
     因为关系到索引量的大小，目前大型搜索引擎服务提供商都将暗网挖掘作为重要的研究方向，Google、百度的"阿拉丁计划"。
     难点：
        1、查询组合太多，如果一一组合遍历，那么会给被访问网站造成巨大压力，所以如何精心组合查询选项是个难点。
           解决：富含信息查询模版(Informative Query Templates)
                ISIT算法：首先从一维模版开始，对一维查询模版逐个考察，看其是否富含信息查询模版，如果是的话，则将这个一维模版
                扩展到二维，再依次考察对应的二维模版，如此类推，逐个增加纬度，直到再也无法找到富含信息查询模版为止。
                Google的评测结果证明，这种方法和完全组合方式比，能够大幅度提升系统效率。
                数据挖掘：Google提出的算法和数据挖掘里经典的Apriori规则挖掘算法。
        2、有的查询是文本框，比如图书搜索中需要输入书名，爬虫怎样能够填入合适的内容，也颇具有挑战性。
           解决：对于输入中的文本框，需要爬虫自动生成查询。
                通过人工观察网站进行定位，提供一个与网站内容相关的初始种子查询关键词表，对于不同的网站，需要人工提供不同的词表，
                以此作为爬虫能够继续工作的基础条件，通过这种人工启发组合递归迭代的方式，尽可能覆盖数据库里的记录。
 ### 分布式爬虫       
     面对海量待抓取网页，只有采用分布式架构，才有可能在较短的时间内完成一轮抓取工作。
     分布式爬虫可以分为若干个分布式层级，不同的应用可能由其中部分层级构成。
     如：分布式爬虫的3个层级：
                        1、分布式数据中心；2、分布式抓取服务器；3、分布式爬虫程序
     常见的分布式架构有两种：
         1:住从式分布爬虫(Master-Slave)
                                        ———URL———>抓取服务器<——————
                                        |                        |
                                        |                        |
            待抓取URL队列---->URL服务器------URL--->抓取服务器<——————————互联网
                                        |                        |
                                        |                        |
                                        ———URL———>抓取服务器<——————
            其中有一台专门负责对其他服务器提供URL分发服务，其他机器则进行实际的网页下载。
            URL服务器维护待抓取URL队列，并从中获得待抓取网页的URL，分配给不同的抓取服务器，另外还要对抓取服务器之间的工作进行
            负载均衡，使得各个服务器承担的工作量大致相等，不至于出现忙的过忙、闲的过闲的情形。抓取服务器之间没有通信联系，每个
            抓取服务器只和URL服务器进行消息传递。
            Google在早期即采用此中主从分布式爬虫，但是此架构URL服务器承担更多的管理任务，同时待抓取URL队列数量巨大，所以URL
            服务器容易成为整个系统的瓶颈。                    
         2:对等式分布爬虫
            在对等式分布式爬虫体系中，服务器之间不存在分工差异，每台服务器承担相同的功能，各自负担一部分URL的抓取工作，Mercator
            爬虫采用此种体系结构。 
                                        ———URL———>抓取服务器<——————
                                        |                        |
                                        |                        |
                    待抓取URL队列-------Hash--URL----->抓取服务器<——————————互联网
                                        |                        |
                                        |                        |
                                        ———URL———>抓取服务器<——————
                    对待抓取URL队列中的URL进行Has取模(hash[URL]%m)。
                    注：m指抓取服务器个数。
                    缺点：抓取过程中某台服务器宕机，或者此时新加入一台抓取服务器，因为取模时m是以服务器个数确定的，所以此时m值
                         发生变化，导致大部分URL哈希取模后的值跟着变化，这意味着几乎所有任务都需要重新进行分配，无疑会导致资源
                         的极大浪费。
                    解决：为了解决哈希取模的对等式分布式爬虫存在的问题，UbiCrawler爬虫提出了改进方案，即放弃哈希取模方式，转而
                         采用一致性哈希方法(Consisting Hash)来确定服务器的任务分工。   
                         一致性哈希将网站的主域名进行哈希，映射为一个范围在0到2^32之间的某个数值，大量的网站主域名会均匀地哈希
                         到这个数值区间。
 ### 搜索引擎索引
     索引好比书籍的目录，目的是为了让人们更快的找到相关章节内容。                        
     如：hao123导航网站本质上也是互联网页面中的索引结构。
     在计算机科学领域，索引也是非常常用的数据结构。其根本目的是为了在具体应用中加快查找速度。
     具体到搜索引擎，索引更是其中最重要的核心技术之一，面对海量的网页内容，如何快速找到包含用户查询词的所有网页？倒排索引在其中扮
     演了关键的角色。
 ### 索引基础
     单词-——文档矩阵：
        搜索引擎的索引其实就是实现单词————文档矩阵的具体数据结构。
        可以有不同的方式实现上述概念模型，比如倒排索引、签名文件、后缀树等方式。但是各项实验数据表明，倒排索引是单词到文档映射关系
        的最佳实现方式。
     倒排索引基本概念：
        倒排索引用到的专用术语：
           文档：一般搜索引擎的处理对象是互联网网页，而文档这个概念要更宽泛些，代表以文本形式存在的存储对象。
                例如：Word、PDF、html、XML、一封邮件、一条短信、一条微博。
           文档集合：由若干个文档构成的集合称为文档集合。比如海量的互联网网页或者说大量的电子邮件。
           文档编号：文档的唯一标识，DocID.
           单词编号：单词的唯一表征。
           倒排索引：倒排索引是实现单词————文档矩阵的一种具体存储形式。通过倒排索引，可以根据单词快速获取包含这个单词的文档列表
                    倒排索引主要由两部分组成：单词词典和倒排文件。
           单词词典：搜索引擎通常的索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串的集合，单词词典内每条索引
                    项记载单词本身的一些信息及指向倒排列表的指针。
           倒排列表：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项
                   （Posting）。根据倒排列表，即可获知哪些文档包含某个单词。              
           倒排文件：倒排单词的倒排列表所在磁盘文件。倒排文件是存储倒排索引的物理文件。
            __________________________________________________________
           |                                                          |
           |   内存中     词典————>单词1   单词2   单词3   单词4   单词5  |
           |_______________________|_______|__________________________|  
                                   |
                              词典指向倒排列表
            _______________________|___________________________________
           |                                                          |
           |                           倒排列表                        |
           |              倒排文件                                     |
           |   磁盘中                                                  |
           |                                                          |   
           |__________________________________________________________|
     
     
     
     
     
     
     
     
     
     

> reubenwang@foxmail.com
> 没事别找我，找我也不在！--我很忙🦆