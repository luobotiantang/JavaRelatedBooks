# 《这就是搜索引擎核心技术详解》相关

 - [搜索引擎的重要地位](#搜索引擎的重要地位)
 
 - [搜索引擎技术发展史](#搜索引擎技术发展史)
 
 - [搜索引擎的3个目标](#搜索引擎的3个目标)
 
 - [搜索引擎的3个核心问题](#搜索引擎的3个核心问题)
 
 - [搜索引擎的技术架构](#搜索引擎的技术架构)
 
 - [搜索引擎架构图](https://www.processon.com/view/link/5ed34f437d9c080702854f3f)
 
 - [网络爬虫](#网络爬虫)
 
 - [通用爬虫框架](#通用爬虫框架)
 
 - [优秀爬虫的特性](#优秀爬虫的特性)
 
 - [爬虫质量的评价标准](#爬虫质量的评价标准)
 
 - [抓取策略](#抓取策略)
 
 ### 搜索引擎的重要地位
     由于目前互联网技术的爆炸性增长，信息过载的问题就目前来说越来越严重，由于互联网个性化的发展趋势越逐步展现，普通用户发布信息的成本
     越来越低，这个问题将会更加严重。这就是搜索引擎越来越重要的基础背景，搜索是目前解决信息过载的相对有效的方式，在没有更有效的替代解
     决方式出来之前，搜索引擎作为互联网网站和应用的入口及处于行业制高点的重要地位只会增强。
     
 ### 搜索引擎技术发展史
     1、分类目录
        采取分类目录的方式，纯人工方式并未采取什么高深的技术。如Yahoo、hao123这个时代的代表。
     2、文本检索
        采用经典的信息检索模型，采用布尔模型、向量空间模型或者概率模型，来查询用户的关键词和网页文本内容的相关程度。但是并未用到网页
        之间丰富的链接关系。早起的搜索引擎如AltaVista、Excite等大都采取这种模式。
     3、链接分析
        充分利用网页的链接关系，并深度挖掘和利用了网页链接所代表的含义。通常而言网页链接代表了一种推荐关系，所以通过链接分析可以在海
        量内容中找到重要的网页。如Google率先提出并使用PageRank链接分析技术。
     4、用户中心
        目前的搜索引擎大都可以归入第三代，即以理解用户需求为核心。
        目前搜索引擎大都致力于解决如下问题：如何能够理解用户发出的某个很短的查询词背后包含的真正需求，所以这一代的搜索引擎称之为以用
                                       户为中心的一代。
 ### 搜索引擎的3个目标
     应用形式：用户输入查询词，搜索引擎返回搜索结果。 
     1、更全
        索引的网页数量。可以通过提高网络爬虫相关技术来达到此目标。
     2、更快
        索引相关技术、缓存等技术的提出都是直接为了达到此目的。                                   
     3、更准
        如何使得搜索结果"更准"是最为关键的目标。(排序技术、链接分析技术、用户研究) 
 ### 搜索引擎的3个核心问题
     搜索引擎如何能够搜得更准是其最重要的目标。如何搜得更准涉及3个核心问题。
     1、用户真正的需求是什么
     2、哪些信息是和用户需求真正相关的
     3、哪些信息是用户可以依赖的      
 ### 搜索引擎的技术架构
     作为互联网应用中最具技术含量的应用之一，优秀的搜索引擎需要复杂的架构和算法，以此来支撑对海量数据的获取、存储，以即对用户查询的快
     速而准确的响应。
 ### 网络爬虫
     网络爬虫的作用
         高效的下载系统，将目前网页数以百亿计的网页数据传送到本地，在本地形成互联网网页的镜像备份。
 ### 通用爬虫框架
     首先从互联网页面中精心选择一部分网页，以这些网页的链接地址作为种子URL，将这些种子URL放入待抓取URL队列中，爬虫从待抓取URL队列依
     次读取，并将URL通过DNS解析，把链接地址转换为网站服务器对应的IP地址。然后将其和网页相对路径名称交给网页下载器，网页下载器负责页
     面内容的下载。对于下载到本地的网页，一方面将其存储到页面库中，等待建立索引等后续处理；另一方面将下载过的网页URL放入已抓取URL队
     列中，这个队列记载了爬虫系统已经下载过的网页URL，以避免网页的重复抓取。对于刚下载的网页，从中抽取所包含的所有链接信息，并在已抓
     取URL队列中检查，如果发现链接还没有被抓取过，则将这个URL放入待抓取URL队列末尾，在之后的抓取调度中会下载这个URL对应的网页。如此
     这般，形成循环，直到待抓取URL队列为空，这代表着爬虫系统已将能够抓取的网页尽数抓完，此时形成了一轮完整的抓取过程。
     爬虫划分以下3种类型
        1、批量型爬虫(Batch Crawler)
           有明确的抓取范围和目标
        2、增量型爬虫(Incremental Crawler)
           更新已有网页
        3、垂直型爬虫(Focused Crawler)
           关注特定主题内容或者属于特定行业的网页
 ### 优秀爬虫的特性
     1、高性能
        爬虫下载网页的抓取速度，常见的评价方式是以爬虫每秒能够下载的网页数量作为性能指标。
     2、可扩展性
        爬虫需要抓取网页数量巨大，即使单个爬虫的性能很高，要将所有网页都下载到本地，仍然需要相当长的时间周期，为了尽可能的缩短时间
        周期，爬虫系统应该有很好的可扩展性，即很容易通过增加抓取服务器和爬虫数量来达到此目的。
        分布式，增加并发性。
     3、健壮性
        服务器宕机，能够恢复之前抓取的内容和数据结构
     4、友好性
        1、保护网站的部分私密性
           A：爬虫禁抓协议
           B：网页禁抓标记
        2、减少抓取网站的网络负载 
           爬虫访问网站频率过高，会给服务器造成很大的访问压力，类似DOS攻击的效果。 
 ### 爬虫质量的评价标准
     1、抓取网页覆盖率
     2、抓取网页时新性
     3、抓取网页重要性
     决定了爬虫系统的质量和性能
        A：抓取策略
        B：网页更新策略
        C：暗网抓取
        D：分布式爬虫
     Google的两套爬虫系统
        A：Fresh Bot(以秒为更新周期)
        B：Deep Crawl Bot(以天为更新周期)           
 ### 抓取策略
     宽度优先遍历策略:
         将新下载网页追加到待抓取URL队列末尾
     非完全PageRank策略:
         PageRank是一种链接分析算法，可以用来衡量网页的重要性.可以用PageRank的思想来对URL优先级进行排序，但这里有个问题，
         PageRank是个全局性算法，也就是说当所有网页都下载完成后，其计算结果才是可靠的，而爬虫的目的是下载网页，在运行中只能看到
         一部分页面，所以在抓取阶段的网页是无法获得可靠的PageRank得分的。
         对于已经下载的网页，加上待抓取URL队列中的URL一起，形成网页集合，在此集合内进行PageRank计算，计算完成后，将带抓取URL队
         列里的网页按照PageRank得分由高到低排序，形成的序列就是爬虫接下来应该依次抓取的URL列表，这也是为何称之为"非完全PageRank"
         的原因。
         如果每次新抓取到一个网页，就将所有已经下载的网页重新计算新的非完全PageRank值，明显效率太低，在现实中是不可行的。一个折中
         的办法是：每当新下载的网页攒够K个，将所有下载页面重新计算一遍新的非完全PageRank,这样的效率还勉强可以接受。
         但是又引来了新的问题：在展开下一轮PageRank计算之前，从新下载的网页抽取出包含的链接，很有可能这些链接的重要性非常高，理应
         优先下载这种情况该如何解决？非完全PageRank赋予这些新抽取出来但是又没有PageRank值的网页一个临时PageRank值，将这个网页的
         所有入链传导的PageRank值汇总，作为临时PageRank值，如果这个值比待抓取URL队列中已经计算出来的PageRank值的网页高，那么就
         优先下载这个URL
     OCIP策略:
         Online Page Importance Computation,在线页面重要性计算，可以将其看作是一种改进的PageRank算法。在算法开始之前，每个互
         联网页面都赋予相同的"现金"cash，每当下载了某个页面P后，P将自己拥有的"现金"平均分配给页面中包含的链接页面，把自己的"现金"
         清空。而对于待抓取URL队列中的网页，则根据手头拥有的现金金额多少排序，优先下载现金最充裕的网页。OCIP从大的框架上与PageRank
         思路基本一致，区别在于：PageRank每次需要迭代计算，而OCIP策略不需要迭代过程，所以计算速度远远快于PageRank，适合实时计算
         使用。
     大站优先策略: 
         以网站为单位来衡量网页的重要性，对于待抓取URL队列中的网页，根据所属网站归类，其本质思想倾向于优先下载大型网站。
     
               
     
  

        
     
     
     
     
     
     
     
     
     
     
     
     
     
     

> reubenwang@foxmail.com
> 没事别找我，找我也不在！--我很忙🦆